{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8faaaff0",
   "metadata": {},
   "source": [
    "## *Transform in ETL*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "42a7774d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.simplefilter('ignore', category=FutureWarning)\n",
    "warnings.simplefilter('ignore', category=ImportWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "150aa97f",
   "metadata": {},
   "source": [
    "# *Transorm-Full*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "92092ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load raw data\n",
    "orders_full = pd.read_csv('data/raw_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddb6ae02",
   "metadata": {},
   "source": [
    "## 1.*Data cleanning*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e6777885",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100 entries, 0 to 99\n",
      "Data columns (total 7 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   order_id       100 non-null    int64  \n",
      " 1   customer_name  99 non-null     object \n",
      " 2   product        100 non-null    object \n",
      " 3   quantity       74 non-null     float64\n",
      " 4   unit_price     65 non-null     float64\n",
      " 5   order_date     99 non-null     object \n",
      " 6   region         75 non-null     object \n",
      "dtypes: float64(2), int64(1), object(4)\n",
      "memory usage: 5.6+ KB\n"
     ]
    }
   ],
   "source": [
    "orders_full.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dd88ea0",
   "metadata": {},
   "source": [
    "### *Remove duplicates*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "69b26000",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for duplicates in the orders_full\n",
    "orders_full.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c1f2f4ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove duplicates\n",
    "orders_full.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d0f9583",
   "metadata": {},
   "source": [
    "#### *Why and how*?\n",
    "\n",
    "*`Action Taken`:* *Removed duplicate rows using `drop_duplicates()`.*\n",
    "\n",
    "*`Reason`:Duplicate records can distort analysis, especially in aggregated reports such as total revenue or units sold. For example, if a transaction appears twice, it would double-count the quantity and revenue, leading to inaccurate business insights. Removing duplicates ensures data integrity and consistency before transformation or loading steps.*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "075b7b7d",
   "metadata": {},
   "source": [
    "####  *Handle missing values*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f6724025",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing customer_name 'Unknown'\n",
    "orders_full['customer_name'] = orders_full['customer_name'].fillna('Unknown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "372c8cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fill missing order_date with a string placeholder\n",
    "orders_full['order_date'] = orders_full['order_date'].fillna('2025-01-01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e3af2922",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing region with 'Not Specified'\n",
    "orders_full['region'] = orders_full['region'].fillna('Not Specified')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75f4f8ef",
   "metadata": {},
   "source": [
    "#### *Why and How*\n",
    "\n",
    "*To ensure data completeness and maintain analysis integrity, the following transformations were applied to columns with missing values:*\n",
    "\n",
    "---\n",
    "\n",
    "#### *1. `customer_name`*  \n",
    "*Action Taken:* *Filled with `\"Unknown\"`*  \n",
    "*Reason:*  \n",
    "*Customer name is a descriptive field and not directly used in calculations. Replacing the missing value with `\"Unknown\"` retains the row while clearly indicating the lack of customer information. This is a common practice in retail datasets where anonymous or guest customers may exist.*\n",
    "\n",
    "---\n",
    "\n",
    "#### *2. `order_date`*  \n",
    "*Action Taken:* *Filled with placeholder `'2025-01-01'`, then converted to `datetime64`*  \n",
    "*Reason:*  \n",
    "*The `order_date` column is crucial for time-based analysis (e.g., trends, monthly summaries). Dropping the row would reduce the dataset, so a placeholder date was used to preserve it. The entire column was then converted to `datetime64[ns]` to support proper chronological sorting, filtering, and aggregation.*\n",
    "\n",
    "---\n",
    "\n",
    "#### *3. `region`*  \n",
    "*Action Taken:* *Filled with `\"Not Specified\"`*  \n",
    "*Reason:*  \n",
    "*Although region is a categorical field, it’s important for geography-based reporting (e.g., revenue by region). Filling missing values with `\"Not Specified\"` helps retain the rows and provides a clear label that the location is unknown, without skewing results for actual regions.*\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a9946bd",
   "metadata": {},
   "source": [
    "### *Contextual Imputation of Missing `unit_price` and `quantity` Values*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e42dcc3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows where both quantity and unit_price are missing\n",
    "orders_full = orders_full.dropna(subset=['quantity', 'unit_price'], how='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "73cce710",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert order_date to datetime and extract month\n",
    "orders_full['order_date'] = pd.to_datetime(orders_full['order_date'])\n",
    "orders_full['month'] = orders_full['order_date'].dt.month"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0c90411",
   "metadata": {},
   "source": [
    "### *Apply Group-Based Imputation for Missing Values*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6057882b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing unit_price using mean of product, month, and region\n",
    "orders_full['unit_price'] = orders_full.groupby(['product', 'month', 'region'])['unit_price'].transform(\n",
    "    lambda x: x.fillna(x.mean())\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89d0b379",
   "metadata": {},
   "source": [
    "#### *Broader Group for unit_price*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c4bb0322",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fill remaining missing unit_price by (product, month)\n",
    "orders_full['unit_price'] = orders_full.groupby(['product', 'month'])['unit_price'].transform(\n",
    "    lambda x: x.fillna(x.mean())\n",
    ")\n",
    "\n",
    "# Then fallback to (product) only\n",
    "orders_full['unit_price'] = orders_full.groupby(['product'])['unit_price'].transform(\n",
    "    lambda x: x.fillna(x.mean())\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8997fc5",
   "metadata": {},
   "source": [
    "#### *Broader Group for quantity*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "99a9b996",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill remaining missing quantity by (product, month)\n",
    "orders_full['quantity'] = orders_full.groupby(['product', 'month'])['quantity'].transform(\n",
    "    lambda x: x.fillna(x.median())\n",
    ")\n",
    "\n",
    "# Then fallback to (product) only\n",
    "orders_full['quantity'] = orders_full.groupby(['product'])['quantity'].transform(\n",
    "    lambda x: x.fillna(x.median())\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "029babff",
   "metadata": {},
   "source": [
    "#### *Why and How:Imputation of Missing `unit_price` and `quantity` Values*\n",
    "\n",
    "*The `unit_price` and `quantity` columns are essential for sales analytics, as they are used to compute key metrics such as revenue and total units sold. Missing values in these fields would compromise the accuracy of downstream analysis.*\n",
    "\n",
    "*To resolve this, a group-based imputation strategy was applied. Initially, the dataset was grouped by `product`, `region`, and `month` — representing logical business dimensions — and missing values were filled using:*\n",
    "\n",
    "- *The **mean** of `unit_price` within each group.*\n",
    "- *The **median** of `quantity` within each group.*\n",
    "\n",
    "*However, due to the absence of sufficient historical records in some groupings, certain values remained missing. To ensure completeness, a fallback mechanism was implemented in the following sequence:*\n",
    "\n",
    "1. *Group by `product` and `month`, and impute missing values.*\n",
    "2. *If still missing, group by `product` alone and impute.*\n",
    "\n",
    "*This tiered approach ensured all missing values were handled meaningfully without resorting to arbitrary global averages. It preserves the contextual integrity of the dataset and supports accurate and reliable transformation for further analysis.*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d3299bb",
   "metadata": {},
   "source": [
    "## *2.Structural Transformations & Data Type Conversion*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8e65abf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert order_id to string/object type\n",
    "orders_full['order_id'] = orders_full['order_id'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "011ea4a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert product and region to pandas 'category' dtype\n",
    "orders_full[['product', 'region']] = orders_full[['product', 'region']].astype('category')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "31f3363b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert order_date column to datetime64[ns]\n",
    "orders_full['order_date'] = pd.to_datetime(orders_full['order_date'],errors='raise', dayfirst=False)  # raise error if any invalid date remains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5a3a4991",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert month column to an integer type\n",
    "orders_full['month'] = orders_full['month'].astype('int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e50844d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert numeric columns to appropriate types\n",
    "orders_full['unit_price'] = orders_full['unit_price'].astype('float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "96a68615",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert quantity to integer, rounding down any non-integer values\n",
    "orders_full['quantity'] = (\n",
    "    np.floor(pd.to_numeric(orders_full['quantity'], errors='coerce'))\n",
    "    .astype('Int64')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b057646",
   "metadata": {},
   "source": [
    "#### *Structural Transformation & Data Type Conversion*\n",
    "\n",
    "*After cleaning and enriching the dataset, we standardize data types to ensure consistency, improve performance, and support downstream analysis.*\n",
    "\n",
    "---\n",
    "\n",
    "#### `order_date` → `datetime64[ns]`  \n",
    "*Converted from string (`object`) to `datetime64[ns]` using `pd.to_datetime()`. This is essential for accurate filtering, sorting, and time-based grouping.*\n",
    "\n",
    "\n",
    "\n",
    "#### `month` → `int32`\n",
    "*Explicitly cast to `int32` to optimize memory usage and confirm its status as a numeric field suitable for grouping operations.* :contentReference[oaicite:2]{index=2}\n",
    "\n",
    "\n",
    "\n",
    "#### `order_id` → `object`  \n",
    "*Converted from numeric to string (`object`) type since it serves as a categorical identifier, not a field for arithmetic operations. This enforces data integrity and prevents unintended numerical computations.*\n",
    "\n",
    "\n",
    "\n",
    "#### `product, region  `→ `category`  \n",
    "*Changed from generic strings to pandas `category` type. This reduces memory usage and improves performance during grouping and filtering operations — especially with repeated values.* \n",
    "\n",
    "\n",
    "\n",
    "#### `quantity, unit_price → float64 (or `Int64` if integer precision is needed)` \n",
    "*Ensures numeric consistency for arithmetic calculations, such as computing `total_price`. Notably, converting to nullable integer (`Int64`) is possible only after ensuring all values are whole numbers and no nulls remain. Any decimal or null values would prevent safe casting.* :contentReference[oaicite:4]{index=4}\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4ca29dc",
   "metadata": {},
   "source": [
    "# *3.Data Enrichment*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "df5e880f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new column: total_price = quantity × unit_price\n",
    "orders_full['total_price'] = orders_full['quantity'] * orders_full['unit_price']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f015eb97",
   "metadata": {},
   "source": [
    "### *Data Enrichment: Computing `total_price`*\n",
    "\n",
    "*Action Taken:A new column, `total_price`, was created by multiplying `quantity` and `unit_price` for each record.*\n",
    "\n",
    "*Reason:*  \n",
    "*The `total_price` field represents transaction-level revenue and is fundamental for sales analytics. It simplifies downstream processes such as region-based revenue, customer lifetime value calculations, and financial reporting by centralizing the key metric for income.*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92d8b57b",
   "metadata": {},
   "source": [
    "# *4.Categorization*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "8830a23a",
   "metadata": {},
   "outputs": [],
   "source": [
    "orders_full['revenue_category'] = pd.cut(orders_full['total_price'], [0,100,500,1000,float('inf')], labels=['Low','Medium','High','Very High'], include_lowest=True, ordered=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c81104f9",
   "metadata": {},
   "source": [
    "### *Categorizing `total_price` with Fixed Bins*\n",
    "\n",
    "*We categorize `total_price` into meaningful business tiers using `pd.cut()` with fixed numeric ranges:*  \n",
    "\n",
    "- **Bins**: 0–100, 100–500, 500–1000, and 1000+  \n",
    "- **Labels**: ‘Low’, ‘Medium’, ‘High’, ‘Very High’\n",
    "\n",
    "*This method segments continuous revenue data into clear, interpretable categories, ideal for business reporting and analysis.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "3f646ca8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 91 entries, 0 to 99\n",
      "Data columns (total 10 columns):\n",
      " #   Column            Non-Null Count  Dtype         \n",
      "---  ------            --------------  -----         \n",
      " 0   order_id          91 non-null     object        \n",
      " 1   customer_name     91 non-null     object        \n",
      " 2   product           91 non-null     category      \n",
      " 3   quantity          91 non-null     Int64         \n",
      " 4   unit_price        91 non-null     float64       \n",
      " 5   order_date        91 non-null     datetime64[ns]\n",
      " 6   region            91 non-null     category      \n",
      " 7   month             91 non-null     int32         \n",
      " 8   total_price       91 non-null     Float64       \n",
      " 9   revenue_category  91 non-null     category      \n",
      "dtypes: Float64(1), Int64(1), category(3), datetime64[ns](1), float64(1), int32(1), object(2)\n",
      "memory usage: 6.4+ KB\n"
     ]
    }
   ],
   "source": [
    "#Check for the  after all transformations\n",
    "orders_full.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "66cfe04a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformed incremental dataset saved as 'transformed/transformed_full.csv'\n"
     ]
    }
   ],
   "source": [
    "# Save the fully transformed dataset to CSV\n",
    "orders_full.to_csv('transformed/transformed_full.csv', index=False)\n",
    "print(\"Transformed incremental dataset saved as 'transformed/transformed_full.csv'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47b288c0",
   "metadata": {},
   "source": [
    "# *Transorm-incremental*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "895e6e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load incremental data\n",
    "orders_incremental = pd.read_csv('data/incremental_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1c25009",
   "metadata": {},
   "source": [
    "## 1.*Data cleanning*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e4b00966",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10 entries, 0 to 9\n",
      "Data columns (total 7 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   order_id       10 non-null     int64  \n",
      " 1   customer_name  4 non-null      object \n",
      " 2   product        10 non-null     object \n",
      " 3   quantity       6 non-null      float64\n",
      " 4   unit_price     10 non-null     float64\n",
      " 5   order_date     10 non-null     object \n",
      " 6   region         8 non-null      object \n",
      "dtypes: float64(2), int64(1), object(4)\n",
      "memory usage: 692.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "orders_incremental .info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50e8aa44",
   "metadata": {},
   "source": [
    "### *Remove duplicates*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "f9967b7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orders_incremental.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d56b499",
   "metadata": {},
   "source": [
    "####  *Handle missing values*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "03809597",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing customer_name 'Unknown'\n",
    "orders_incremental['customer_name'] = orders_incremental['customer_name'].fillna('Unknown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "bbfcef35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing region with 'Not Specified'\n",
    "orders_incremental['region'] = orders_incremental['region'].fillna('Not Specified')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7041ab64",
   "metadata": {},
   "source": [
    "### *Contextual Imputation of Missing `quantity` Values*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "c4574aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows where both quantity and unit_price are missing\n",
    "orders_incremental = orders_incremental.dropna(subset=['quantity', 'unit_price','region'], how='all')\n",
    "# Convert order_date to datetime and extract month\n",
    "orders_incremental['order_date'] = pd.to_datetime(orders_incremental['order_date'])\n",
    "orders_incremental['month'] = orders_incremental['order_date'].dt.month\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "0a73b407",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill remaining missing quantity by (product, month)\n",
    "orders_incremental['quantity'] = orders_incremental.groupby(['product', 'month'])['quantity'].transform(\n",
    "    lambda x: x.fillna(x.median()))\n",
    "\n",
    "\n",
    "# Then fallback to (product) only\n",
    "orders_incremental['quantity'] = orders_incremental.groupby(['product'])['quantity'].transform(\n",
    "    lambda x: x.fillna(x.median()))\n",
    "orders_incremental = orders_incremental.dropna(subset=['quantity'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d4dd845",
   "metadata": {},
   "source": [
    "## *2.Structural Transformations & Data Type Conversion*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "ce6454bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert order_id to string/object type\n",
    "orders_incremental['order_id'] = orders_incremental['order_id'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "2486b4c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert product and region to pandas 'category' dtype\n",
    "orders_incremental[['product', 'region']] = orders_incremental[['product', 'region']].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "ed50dd51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert quantity to integer, rounding down any non-integer values\n",
    "orders_incremental['quantity'] = ( np.floor(pd.to_numeric(orders_incremental['quantity'], errors='coerce')).astype('Int64'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9c8e168",
   "metadata": {},
   "source": [
    "# *3.Data Enrichment*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "47e40918",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new column: total_price = quantity × unit_price\n",
    "orders_incremental['total_price'] = orders_incremental['quantity'] * orders_incremental['unit_price']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15a4417e",
   "metadata": {},
   "source": [
    "# *4.Categorization*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "ad62a014",
   "metadata": {},
   "outputs": [],
   "source": [
    "orders_incremental['revenue_category'] = pd.cut(orders_incremental['total_price'], [0,100,500,1000,float('inf')], labels=['Low','Medium','High','Very High'], include_lowest=True, ordered=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "2e7fb3cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 9 entries, 0 to 8\n",
      "Data columns (total 10 columns):\n",
      " #   Column            Non-Null Count  Dtype         \n",
      "---  ------            --------------  -----         \n",
      " 0   order_id          9 non-null      object        \n",
      " 1   customer_name     9 non-null      object        \n",
      " 2   product           9 non-null      category      \n",
      " 3   quantity          9 non-null      Int64         \n",
      " 4   unit_price        9 non-null      float64       \n",
      " 5   order_date        9 non-null      datetime64[ns]\n",
      " 6   region            9 non-null      category      \n",
      " 7   month             9 non-null      int32         \n",
      " 8   total_price       9 non-null      Float64       \n",
      " 9   revenue_category  9 non-null      category      \n",
      "dtypes: Float64(1), Int64(1), category(3), datetime64[ns](1), float64(1), int32(1), object(2)\n",
      "memory usage: 1.0+ KB\n"
     ]
    }
   ],
   "source": [
    "#Check for the  after all transformations\n",
    "orders_incremental.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "85e9ea23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformed incremental dataset saved as 'transformed/transformed_incremental.csv'\n"
     ]
    }
   ],
   "source": [
    "# Save the fully transformed dataset to CSV\n",
    "orders_incremental.to_csv('transformed/transformed_incremental.csv', index=False)\n",
    "print(\"Transformed incremental dataset saved as 'transformed/transformed_incremental.csv'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
